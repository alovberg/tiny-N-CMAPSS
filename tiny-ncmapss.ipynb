{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "source": [
    "## Train set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## According to competition FAQ, use all files except N-CMAPSS_DS02-006 and N-CMAPSS_DS08d-010\n",
    "filenames = ['N-CMAPSS_DS01-005.h5','N-CMAPSS_DS03-012.h5', 'N-CMAPSS_DS04.h5', 'N-CMAPSS_DS05.h5', 'N-CMAPSS_DS06.h5','N-CMAPSS_DS07.h5','N-CMAPSS_DS08a-009.h5', 'N-CMAPSS_DS08c-008.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_var = ['unit', 'cycle', 'Fc', 'hs']\n",
    "X_s_var =  ['T24',\n",
    "            'T30',\n",
    "            'T48',\n",
    "            'T50',\n",
    "            'P15',\n",
    "            'P2',\n",
    "            'P21',\n",
    "            'P24',\n",
    "            'Ps30',\n",
    "            'P40',\n",
    "            'P50',\n",
    "            'Nf',\n",
    "            'Nc',\n",
    "            'Wf']\n",
    "W_var = ['alt', 'Mach', 'TRA', 'T2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading file N-CMAPSS_DS01-005.h5\n",
      "Loading file N-CMAPSS_DS03-012.h5\n",
      "Loading file N-CMAPSS_DS04.h5\n",
      "Loading file N-CMAPSS_DS05.h5\n",
      "Loading file N-CMAPSS_DS06.h5\n",
      "Loading file N-CMAPSS_DS07.h5\n",
      "Loading file N-CMAPSS_DS08a-009.h5\n",
      "Loading file N-CMAPSS_DS08c-008.h5\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "unit_numbers = [0,10,25,35,45,55,65,80]\n",
    "\n",
    "for j, filename in enumerate(filenames):\n",
    "\n",
    "    print('Loading file', filename)\n",
    "\n",
    "    with h5py.File(filename, 'r') as hdf:\n",
    "\n",
    "        # Development set\n",
    "        W_dev = np.array(hdf.get('W_dev'))             # W\n",
    "        X_s_dev = np.array(hdf.get('X_s_dev'))         # X_s\n",
    "        Y_dev = np.array(hdf.get('Y_dev'))             # RUL  \n",
    "        A_dev = np.array(hdf.get('A_dev'))             # Auxiliary\n",
    "\n",
    "        # \"Test\" set\n",
    "        W_test = np.array(hdf.get('W_test'))           # W\n",
    "        X_s_test = np.array(hdf.get('X_s_test'))       # X_s\n",
    "        Y_test = np.array(hdf.get('Y_test'))           # RUL  \n",
    "        A_test = np.array(hdf.get('A_test'))           # Auxiliary\n",
    "\n",
    "        W = np.concatenate((W_dev, W_test), axis=0)  \n",
    "        X_s = np.concatenate((X_s_dev, X_s_test), axis=0)\n",
    "        Y = np.concatenate((Y_dev, Y_test), axis=0) \n",
    "        A = np.concatenate((A_dev, A_test), axis=0)\n",
    "\n",
    "    df = pd.DataFrame(data=A, columns=A_var)\n",
    "    for i, varname in enumerate(X_s_var):\n",
    "        df[varname] = X_s[:,i]\n",
    "    for i, varname in enumerate(W_var):\n",
    "        df[varname] = W[:,i]\n",
    "\n",
    "    df['unit'] += unit_numbers[j]\n",
    "    df['RUL'] = Y\n",
    "\n",
    "    if len(train_df) == 0:\n",
    "        train_df = df\n",
    "    else:\n",
    "        train_df = pd.concat([train_df,df],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "       27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
       "       40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52.,\n",
       "       53., 54., 55., 56., 57., 58., 59., 60., 61., 62., 63., 64., 65.,\n",
       "       66., 67., 68., 69., 70., 71., 72., 73., 74., 75., 76., 77., 78.,\n",
       "       79., 80., 81., 82., 83., 84., 85., 86., 87., 88., 89., 90.])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_df.unit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This mainly reduces file size by chaning sensor values from float64 to float16 -> significant reduction in size.\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memory usage of dataframe is 11605.79 MB\n",
      "Memory usage after optimization is: 3203.68 MB\n",
      "Decreased by 72.4%\n"
     ]
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downsample by factor 100 (!!)\n",
    "for unit in train_df.unit.unique():\n",
    "  train_df.loc[train_df['unit']==unit] = train_df[train_df['unit']==unit].iloc[::100]\n",
    "\n",
    "train_df = train_df.dropna()"
   ]
  },
  {
   "source": [
    "## Test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Data_Challenge_2021_N-CMAPSS_DS_Validation_f.h5'\n",
    "with h5py.File(filename, 'r') as hdf:\n",
    "        # Development set\n",
    "        W_val = np.array(hdf.get('W_val'))             # W\n",
    "        X_s_val = np.array(hdf.get('X_s_val'))         # X_s\n",
    "        A_val = np.array(hdf.get('A_val'))             # Auxiliary\n",
    "\n",
    "# Create dataframe with Aux array\n",
    "test_df = pd.DataFrame(data=A_val, columns=A_var)\n",
    "\n",
    "# Sensor values\n",
    "for i,varname in enumerate(X_s_var):\n",
    "    test_df[varname] = X_s_val[:,i]\n",
    "\n",
    "# Flight settings\n",
    "for i,varname in enumerate(W_var):\n",
    "    test_df[varname] = W_val[:,i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Memory usage of dataframe is 2807.42 MB\n",
      "Memory usage after optimization is: 701.85 MB\n",
      "Decreased by 75.0%\n"
     ]
    }
   ],
   "source": [
    "test_df = reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit in test_df.unit.unique():\n",
    "  test_df.loc[test_df['unit']==unit] = test_df[test_df['unit']==unit].iloc[::100]\n",
    "\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "source": [
    "## Save"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_df.pkl')\n",
    "test_df.to_pickle('test_df.pkl')"
   ]
  }
 ]
}